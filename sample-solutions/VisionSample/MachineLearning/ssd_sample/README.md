# TensorFlow MobileNet V2 SSD Models

## MobileNet V2 SSD model pre-trained on the COCO dataset: ssd_mobilenet_v2_coco
  - Download and expand the pre-trained [**ssd_mobilenet_v2_coco model**](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz).
  - Copy the extracted **frozen_inference_graph.pb** to **VisionSample\MachineLearning\models\ssd_mobilenet_v2_coco** folder.
  - Overwrite **current_config.py** by **ssd_mobilenet_v2_coco.py** in **VisionSample\MachineLearning\scripts\model_configs** folder.
  - Launch **Visual Studio Code** and execute **01-convert-model-containerize.py** in **VisionSample\MachineLearning\scripts** folder to convert model, create a container image and generate **deployment.json** for deploying the pre-trained **ssd_mobilenet_v2_coco** model.

---
## Sample to retrain a Quantized MobileNet V2 SSD model with a custom dataset poker3

### Content for poker3 folder
- **image\*.tfrecord** files in **data\train** and **data\test** folders are the train and the test data used to train a new **ssd_mobilenet_v2_quantized model**. They are generated by [**Microsoft VoTT: Visual Object Tagging Tool v1.7.2**](https://github.com/Microsoft/VoTT).
- **tf_label_map.pbtxt** in **config** folder is the label map file for **poker3** dataset and there are **3** object classes: **Ace**, **Seven**, and **King**.
- **ssd_mobilenet_v2_quantized_300x300_coco.config** in **config** folder is modified from https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config file.  Major modifications:
  - **num_classes** property;
  - **fine_tune_checkpoint** property;
  - **input_path** and **label_map_path** properties defined in **train_input_reader** and **eval_input_reader** sections. 
- **object_detection_ssd_mobilenet_v2_retrain_poker3.ipynb** is modified from https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb file and used to evaluate the accruacy for the retrained **frozen_inference_graph.pb**.
- **detection1.jpg** and **detection2.jpg** in **test_results** folder are the detection results for the retraind **ssd_mobilenet_v2_quantized** model with **poker3** dataset.

### Retrain and export steps under Windows 10

1. Create a new Windows 10 v1809 Azure VM or prepare a clean installed Windows 10 environment.
1. Install [Anaconda Python 3.7 for Windows version](https://www.anaconda.com/distribution/).
1. Launch **Anaconda Prompt** and execute the following commands:
    ```<language>
    conda install tensorflow
    ```
1. Install COCO API for Windows version.  Refer to [COCO API support Windows build](https://github.com/philferriere/cocoapi) for more detail.
    * Install [git for Windows version](https://git-scm.com/download/win).
    * Install [Visual C++ 2015 build tools](https://go.microsoft.com/fwlink/?LinkId=691126).
    * Launch **Anaconda Prompt** and install COCO API for Windows version by executing the following command:
      ```<language>
      pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
      ```
1. Download or clone [TensorFlow Models](https://github.com/tensorflow/models/).
1. Add a new **tf** subfolder under **c:\\**, rename the extracted directory named **models-master** to **models**, and copy the full **models** directory to **c:\tf** directory.
1. Add the following system environment variable:
    ```<language>
    PYTHONPATH=c:\tf\models;c:\tf\models\research;c:\tf\models\research\slim 
    ```
1. Launch **Anaconda Prompt**, change directory to **c:\tf\models\research**, and execute the following commands:
    ```<language>
    protoc --python_out=. .\object_detection\protos\anchor_generator.proto .\object_detection\protos\argmax_matcher.proto ^
    .\object_detection\protos\bipartite_matcher.proto .\object_detection\protos\box_coder.proto .\object_detection\protos\box_predictor.proto ^
    .\object_detection\protos\calibration.proto .\object_detection\protos\eval.proto ^
    .\object_detection\protos\faster_rcnn.proto .\object_detection\protos\faster_rcnn_box_coder.proto ^
    .\object_detection\protos\graph_rewriter.proto .\object_detection\protos\grid_anchor_generator.proto ^
    .\object_detection\protos\hyperparams.proto .\object_detection\protos\image_resizer.proto .\object_detection\protos\input_reader.proto ^
    .\object_detection\protos\keypoint_box_coder.proto .\object_detection\protos\losses.proto ^
    .\object_detection\protos\matcher.proto .\object_detection\protos\mean_stddev_box_coder.proto ^
    .\object_detection\protos\model.proto .\object_detection\protos\multiscale_anchor_generator.proto ^
    .\object_detection\protos\optimizer.proto .\object_detection\protos\pipeline.proto .\object_detection\protos\post_processing.proto ^
    .\object_detection\protos\preprocessor.proto .\object_detection\protos\region_similarity_calculator.proto ^
    .\object_detection\protos\square_box_coder.proto .\object_detection\protos\ssd.proto ^
    .\object_detection\protos\ssd_anchor_generator.proto .\object_detection\protos\string_int_label_map.proto ^
    .\object_detection\protos\train.proto
    ```
    ```<language>
    python setup.py build
    python setup.py install
    ```
1. Download and expand [**ssd_mobilenet_v2_quantized_coco model**](http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz).
1. Copy the extracted **ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03** folder to **c:\tf\models\research\object_detection** folder.
1. Copy **poker3** folder to **c:\tf** folder.
1. Launch **Anaconda Prompt**, change directory to **c:\tf\models\research\object_detection** and execute the following command to retrain a new **ssd_mobilenet_v2_quantized** model with **poker3** dataset:
    ```<language>
    python model_main.py --pipeline_config_path=c:\tf\poker3\config\ssd_mobilenet_v2_quantized_300x300_coco.config ^
                         --model_dir=c:\tf\poker3\models\ssd_mobilenet_v2_quantized\ ^
                         --num_train_steps=4000 ^
                         --sample_1_of_n_eval_examples=3 ^
                         --alsologtostderr 
    ```
    >**Note**: Refer to [Running Locally](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md) for more detail about how to train an object detection model on a local machine.
1. Launch **Anaconda Prompt**, change directory to **C:\tf\models\research\object_detection** and execute the following command to generate a new **frozen_inference_graph.pb** in **c:\tf\poker3\frozen_graph** folder (rename **model.ckpt-4000** to be the **model.ckpt-xxx** file generated in **c:\tf\poker3\models\ssd_mobilenet_v2_quantized** folder):
    ```<language>
    python export_inference_graph.py --input_type=image_tensor ^
                                     --pipeline_config_path=c:\tf\poker3\config\ssd_mobilenet_v2_quantized_300x300_coco.config ^
                                     --trained_checkpoint_prefix=c:\tf\poker3\models\ssd_mobilenet_v2_quantized\model.ckpt-4000 ^
                                     --output_directory=c:\tf\poker3\frozen_graph 
    ```
    >**Note**: Refer to [Exporting a trained model for inference](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/exporting_models.md) for more detail about how to export a trained model to a TensorFlow graph proto.
1. Launch **Anaconda Prompt**, change directory to **C:\tf\models\research\object_detection** and execute the following 2 commands to generate a new TensorFlow Lite model file **detect.tflite** in **c:\tf\poker3\tflite** folder (rename **model.ckpt-4000** to be the **model.ckpt-xxx** file generated in **c:\tf\poker3\models\ssd_mobilenet_v2_quantized** folder):
    ```<language>
    python export_tflite_ssd_graph.py  --pipeline_config_path=C:\tf\poker3\frozen_graph\pipeline.config ^
                                       --trained_checkpoint_prefix=C:\tf\poker3\models\ssd_mobilenet_v2_quantized\model.ckpt-4000 ^
                                       --output_directory=C:\tf\poker3\tflite ^
                                       --add_postprocessing_op=true 

    toco --graph_def_file=C:\tf\poker3\tflite\tflite_graph.pb ^
         --output_file=C:\tf\poker3\tflite\detect.tflite ^
         --output_format=TFLITE --input_shapes=1,300,300,3  ^
         --input_arrays=normalized_input_image_tensor ^
         --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 ^
         --inference_type=QUANTIZED_UINT8 ^
         --mean_values=128 ^
         --std_dev_values=128 ^
         --change_concat_input_ranges=false ^
         --allow_custom_ops ^
         --allow_nonexistent_arrays 
    ```
    >**Note**: Refer to [Training and serving a real-time mobile object detector in 30 minutes](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193) for more detail about how to export a trained TensorFlow Lite model.

### Deploy ssd_mobilenet_v2_quantized_retrain_poker3 model:
- Copy the new **frozen_inference_graph.pb** generated by the above retrain steps to Visual Studio Code sample VisionSample\MachineLearning\models\ssd_mobilenet_v2_quantized_retrain_poker3 folder.
- Overwrite **current_config.py** by **ssd_mobilenet_v2_quantized_retrain_poker3.py** in VisionSample\MachineLearning\scripts\model_configs folder.
- Launch **Visual Studio Code** and execute **01-convert-model-containerize.py** in VisionSample\MachineLearning\scripts folder to convert model, create a container image and generate **deployment.json** for deploying the new **ssd_mobilenet_v2_retrain_poker3** model.

### Deploy TensorFlow Lite model:
- Copy the new **detect.tflite** generated by the above retrain steps to Visual Studio Code sample VisionSample\CreateAndDeployEdgeContainer\modules\VisionSampleModule\model folder.
- Copy **labelmap.txt** and **va-snpe-engine-library_config.json** file from VisionSample\MachineLearning\ssd_sample\poker3\tflite folder to the VisionSample\CreateAndDeployEdgeContainer\modules\VisionSampleModule\model folder.
- Refer to [CreateAndDeployEdgeContainer/README.md](../../CreateAndDeployEdgeContainer/README.md) to build a local container image and deploy the TensorFlow Lite Object Detection Model.

---
## Retrain TensorFlow Object Detection Models on Linux and MacOS

Refer to [Tensorflow Object Detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/README.md) for more detail.
    
